# app.py
# ç®€åŒ–ç‰ˆ Streamlit ä¸­æ–‡å¸ƒå°”æ£€ç´¢ Dashboard
# è¿è¡Œï¼šstreamlit run app.py

import re
import requests
import pandas as pd
import streamlit as st
from collections import defaultdict

st.set_page_config(page_title="ä¸­æ–‡æ–‡æœ¬æ£€ç´¢ Dashboard", layout="wide", page_icon="ğŸ”")

st.title("ğŸ” ä¸­æ–‡æ–‡æœ¬æ£€ç´¢ Dashboard")
st.caption("ä» GitHub è¯»å–å¸¦è¯æ€§æ ‡æ³¨çš„æ–‡æœ¬ï¼Œé€šè¿‡å¸ƒå°”é€»è¾‘ (AND/OR/NOT) æ£€ç´¢å¥å­ã€‚")

# ------------------------
# åœ¨è¿™é‡Œå†…ç½®ä½ çš„ GitHub RAW æ–‡æœ¬åœ°å€
# ------------------------
GITHUB_FILES = {
    "è·¯é¥ã€Šå¹³å‡¡çš„ä¸–ç•Œã€‹": "https://raw.githubusercontent.com/Dittonal/streamlit_search_txt/main/è·¯é¥ã€Šå¹³å‡¡çš„ä¸–ç•Œã€‹_pos.txt",
    "è€èˆã€Šéª†é©¼ç¥¥å­ã€‹": "https://raw.githubusercontent.com/Dittonal/streamlit_search_txt/main/è€èˆã€Šéª†é©¼ç¥¥å­ã€‹_pos.txt",
    "ç‹å®‰å¿†ã€Šé•¿æ¨æ­Œã€‹": "https://raw.githubusercontent.com/Dittonal/streamlit_search_txt/main/ç‹å®‰å¿†ã€Šé•¿æ¨æ­Œã€‹_pos.txt",
    "å¼ çˆ±ç²ã€ŠåŠç”Ÿç¼˜ã€‹": "https://raw.githubusercontent.com/Dittonal/streamlit_search_txt/main/å¼ çˆ±ç²ã€ŠåŠç”Ÿç¼˜ã€‹_pos.txt",
}

@st.cache_data(show_spinner=False)
def fetch_text(url: str) -> str:
    try:
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            r.encoding = r.apparent_encoding or "utf-8"
            return r.text
    except Exception:
        pass
    return ""

def split_sentences(text: str):
    """ç®€å•ä¸­æ–‡åˆ†å¥"""
    text = re.sub(r"[ \t]+", " ", text.strip())
    return [s.strip() for s in re.split(r"[ã€‚ï¼ï¼Ÿ!?ï¼›;]\s*|\n+", text) if s.strip()]

def get_words(sentence: str):
    """æå–è¯ï¼ˆå¿½ç•¥è¯æ€§ï¼‰"""
    words = []
    for t in sentence.split():
        if "/" in t:
            w, _ = t.split("/", 1)
            words.append(w)
        else:
            words.append(t)
    return words

def eval_query(query: str, words: list):
    """æœ€ç®€ç‰ˆå¸ƒå°”é€»è¾‘ AND/OR/NOT"""
    q = query.upper().replace("(", " ( ").replace(")", " ) ")
    tokens = [t for t in q.split() if t]

    def term_match(term):
        return term.lower() in [w.lower() for w in words]

    stack = []
    for t in tokens:
        if t == "NOT":
            if stack:
                stack[-1] = not stack[-1]
        elif t == "AND":
            stack.append("AND")
        elif t == "OR":
            stack.append("OR")
        elif t == "(" or t == ")":
            # ç®€åŒ–ï¼šå¿½ç•¥æ‹¬å·
            continue
        else:
            stack.append(term_match(t))
    # é¡ºåºæ‰§è¡Œï¼šNOT å·²å¤„ç†ï¼Œå‰©ä¸‹ AND/OR å·¦åˆ°å³
    result = None
    op = None
    for item in stack:
        if isinstance(item, bool):
            if result is None:
                result = item
            elif op == "AND":
                result = result and item
            elif op == "OR":
                result = result or item
        else:
            op = item
    return bool(result)

# ------------------------
# è¾“å…¥ä¸ä¸‹è½½
# ------------------------
query = st.text_input("è¾“å…¥æ£€ç´¢è¯ï¼ˆæ”¯æŒ AND / OR / NOTï¼‰ï¼š", value="å¥³äºº AND çˆ±")

corpus = {}
sentences_map = {}
for name, url in GITHUB_FILES.items():
    raw = fetch_text(url)
    corpus[name] = raw
    sentences_map[name] = split_sentences(raw) if raw else []

# ------------------------
# æ£€ç´¢ä¸ç»Ÿè®¡
# ------------------------
rows = []
match_counts = defaultdict(int)

for fname, sents in sentences_map.items():
    for idx, s in enumerate(sents, start=1):
        words = get_words(s)
        if eval_query(query, words):
            rows.append({"æ–‡ä»¶": fname, "å¥å·": idx, "å¥å­ï¼ˆå«è¯æ€§ï¼‰": s})
            match_counts[fname] += 1

# ------------------------
# Dashboard æŒ‡æ ‡
# ------------------------
total = sum(match_counts.values())
cols = st.columns(5)
cols[0].metric("æ€»åŒ¹é…å¥å­æ•°", total)
for i, name in enumerate(GITHUB_FILES.keys()):
    cols[i+1].metric(name, match_counts.get(name, 0))

# ------------------------
# å›¾è¡¨ä¸è¡¨æ ¼
# ------------------------
summary = pd.DataFrame({
    "æ–‡ä»¶": list(GITHUB_FILES.keys()),
    "åŒ¹é…å¥å­æ•°": [match_counts.get(n, 0) for n in GITHUB_FILES.keys()]
})
# st.bar_chart(summary.set_index("æ–‡ä»¶"))

st.markdown("### æ£€ç´¢ç»“æœï¼ˆå«è¯æ€§ï¼‰")
if rows:
    st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
else:
    st.info("æœªæ£€ç´¢åˆ°åŒ¹é…ç»“æœã€‚")

